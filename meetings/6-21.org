* Evolutionary simulation
** Issue with saving the fit to evaluate performance
  - There is an undocumented option that generates a complete log of the program in JSON
    - Not working now, but the maintainer is quite responsive
    - I don't want to use /Eureqa/
      - Non-free, only old versions free
    - Nor =ExprOptimization.jl=, seems quite worse
  - I will have to parse the JSON
    - Easy I think
  - Creates quite a bit of overhead, but I can do runs without the JSON exporter to estimate time
** They return the whole Pareto frontier of complexity vs loss
- Just select the best one for the report (?)
  - Maybe there aren't big differences from some point in complexity onwards
- That's a nice idea for the Bayesian Algorithm as well
  - But not for the report
** How many iterations to run
- Hard to compare... I'm just gonna choose a number of iterations that roughly matches the runtime of the Bayesian algorithm
* Symbolics
- =SymbolicRegression.jl= use the old API from Symbolics
  - Issue with compatibility
  - They need to rewrite to the new Symbolics API
    - Which is /worse/ for our use case, but seems more elegant
- I got a nice response from the Symbolics people
  - Need to use the lower interface =SymbolicUtils.jl=
    - Redefine a new type that behaves as Real except for the rules we don't wanna use
    - Relatively straightforward
  - Fine for the report
  - Not ideal to toggle dynamically with custom grammars
- It might be nicer to interface directly with =SymbolicUtils.jl= directly
  - The interface is quite nice
  - https://symbolicutils.juliasymbolics.org/interface/#similartermtmytype_f_args_t
  - But maybe not right now :)
* Python
- pipenv
- ~ julialike
* Introduction
- Almost done
- Changed the order of a few things
- No major changes in exposition / arguments
  - Except cutting the emphasis on "prior information / structure"
- Over the word limit... but it's fine because shorter procedure and no word limit for results/conclusions
* Bayesian result conclusion
- The algorithm struggles to generate good proposals
- The proposals that are accepted stay as a sample for multiple iterations
- It is very unlikely that a new sample is going to be worse than the previous sample
  - Almost always jumps to a better proposal
  - Lack of /directionality/
- We cannot say that the sample distribution approximates in any way the posterior space
- Therefore not really any statistical advantage from Bayesianism
  - We cannot say anything about our confidence on the tree structure / parameters
  - The most parameters that are potentially interesting (e.g. the distribution of tree complexity) are hyper parameters
* Almost everything is almost done
- Except ::
  - Results + conclusions
  - Real-data example
- Introduction fully written this afternoon/tomorrow ready for feedback
- Evolutionary & Symbolics next & Run python next
- Aiming to finish on the week of the 5th
* Next meeting
- 30th/1st
