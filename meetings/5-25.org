* Jin's [[https://github.com/ying531/MCMC-SymReg/tree/master/codes][code]]
- ...What a mess D:
- They include things in different parts
  - P(\sigma_{a|b}) in h()
  - P(\Theta) in f(\Theta|S)
** Ratio calculation
*** No RJMCMC
- They don't use P(\Theta) and they don't include it in the paper
  - But I think they should
  - =codes/funcs.py:1284,1285=
    - They select only ~fStruc[0]~
- They don't use P(\Sigma_a)/P(\Sigma_b) and they don't include it in the paper
  - But I think they should
  - They include it on the RJMCMC case with h()
- They *use* P(\Sigma_\varepsilon) but they *don't* include in the paper
*** RJMCMC
- They use P(\Sigma) and they include in the paper equation
- They use P(\Theta) and they include it in the paper equation
*** Edge cases
- Shrinking to 0 linear operators
- Expanding from 0 linear operators
- I'm setting h() or h‚Å∫() = 0 for the respective edge case
  - Like Jin
- They include the prior probability of variances that are not used
  - I don't
* State of the code
** Migrated BayesianSR to its own [[https://github.com/cobac/BayesianSR][repo]]
*** Each analysis with a different branch/commit to have reproducible state
- =scripts/jin-vanilla= uses =BayesianSR#jin-vanilla=
- =scripts/centered-proposals= uses =BayesianSR#centered-proposals=
- =scripts/centered-proposals-and-symplify= uses =BayesianSR#master@whatever=
** =[compat]= section of =Project.tml=
- =ExprRules.jl= to include the ~insert!()~ bug fix
- The rest... more recent?
** Spaghetti
  - Works, so ok for now
  - If if works nicely I might rewrite it after the internship
  - And nicer user-facing functions
    - Input validation, graphs, latexify, etc.
** OLS optimization thing
- https://github.com/cobac/resma-internship/pull/2#discussion_r628047547

* Performance
- Something is not working sometimes (eq_3), need to look into it
  - =NaNs= on first chain, and then it has to reject every proposal
- It accepts an extremely low number of samples
  - <50/1000, <50/10000
- Numerical fit can be excellent
  - The low acceptance rate could be that it converges very quickly, but it is not always the case
  - It is hard to find good proposals
- The expressions sometimes are messier
  - The simplify step should fix this
- A lot of variability between chains
  - Probably good idea to run multiple chains if the simplification step does not address it
  - Time-free as we can do it in parallel
  - Low memory footprint
- Computationally is very fast
  - ~8ms per sample on my laptop
  - We'll see how it compares to the python version
* Next steps
** Small stuff
- Look into the (possible) bugs
- Nice way to get the resulting expressions into Julia expressions
** Main things
1. Start outlining the report / rewriting the proposal
2. Implement the modifications to Jin's algorithm and test
   - Functions & simple dataset
3. Get Jin's code working and test
   - Functions & simple dataset
4. Evolutionary symbolic regression
   - Functions & simple dataset
*** The interesting things
**** Bayesian things
- How to select the best trees
- How to get uncertainty over trees/branches
- Should be /easy/ to identify where do things vary with these low acceptance rates
- But maybe if it's hard to explore good samples the frequencies are not informative
**** Fancy expression recovery
- Biased neural networks to abstract functions and recovering expressions from them
  - Cranmer et al.
- Sparse regression/identification from SciML
  - They usually recover mathematical expressions from neural nets
- Compare vs structure into the data
  - You can include the structure information into the functions, or just as a way of structuring the data
    
